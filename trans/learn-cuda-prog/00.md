# 零、前言

Don't take rest after your first victory. Because if you fail in second, more lips are waiting to say that your first victory was just luck. - A. P. J. Abdul Kalam

传统上，计算需求与**中央处理器** ( **中央处理器**相关联，中央处理器已经从单核发展到现在的多核。每一代新的中央处理器都提供了更高的性能，但科学和**高性能计算** ( **高性能计算**)社区对性能的要求逐年提高，这在应用的需求和硬件/软件堆栈的能力之间造成了计算差距。与此同时，传统上用于视频图形的新架构进入了科学领域。**图形处理单元**(**GPU**)——本质上是用于加速计算机图形的并行计算处理器——在 2007 年**计算统一设备架构** ( **CUDA** )推出时就在 HPC 领域崭露头角。在通用计算中使用图形处理器时，CUDA 逐渐成为事实上的标准；也就是非图形应用。

CUDA 从一开始就有很多版本，现在 CUDA 已经到了 10.x 版本，每个版本都提供了支持新硬件架构的新特性。这本书旨在帮助你学习 GPU 并行编程，并指导你在它的现代应用。在它的帮助下，您将能够发现现代图形处理器架构的 CUDA 编程方法。这本书不仅将指导您了解 GPU 特性、工具和 API，还将帮助您了解如何使用示例并行编程算法分析性能。这本书将确保你获得大量的优化经验和对具有各种库、开放加速器(OpenACC)和其他语言的 CUDA 编程平台的见解。随着您的进步，您将发现如何利用一个盒子或多个盒子中的多个图形处理器产生额外的计算能力。最后，您将探索 CUDA 如何加速深度学习算法，包括**卷积神经网络** ( **CNNs** )和**递归神经网络** ( **RNNs** )。

这本书旨在成为任何新来者或新手开发者的切入点。但是到最后，您将能够为不同的领域编写优化的 CUDA 代码，包括人工智能。

如果以下任何一项适用于您，这本书将是一个有用的资源:

*   您不熟悉高性能计算或并行计算
*   你有代码，并希望通过将并行计算应用于 GPU 来提高它的性能
*   您是深度学习专家，希望利用 GPU 来提高深度学习算法(如 CNNs 和 RNNs)的性能
*   您想学习优化代码和分析 GPU 应用性能以及发现优化策略的技巧和诀窍
*   您想了解最新的 GPU 功能，以及高效的分布式多 GPU 编程

如果你觉得自己属于其中任何一类，请加入我们的旅程。

# 这本书是给谁的

这本书是为那些想深入研究并行计算，成为高性能计算社区的一部分并构建现代应用的程序员编写的。假设有基本的 C 和 C++ 编程经验。对于深度学习爱好者来说，这本书涵盖了 Python InterOps、DL 库以及性能评估的实际例子。

# 充分利用这本书

这本书是为完全初学者和刚刚开始学习并行计算的人设计的。除了计算机体系结构的基础知识之外，它不需要任何特定的知识，并且假设有 C/C++ 编程的经验。对于深度学习爱好者来说，在[第 10 章](10.html)、*用 CUDA* 进行深度学习加速时，也提供了基于 Python 的示例代码，因此预计该章会有一些 Python 知识。

这本书的代码主要是在 Linux 环境中开发和测试的。因此，熟悉 Linux 环境是有帮助的。任何最新的 Linux 风格，比如 CentOS 或者 Ubuntu，都可以。可以使用 makefile 或命令行编译代码。这本书主要使用自由软件栈，所以不需要购买任何软件许可证。将贯穿始终的两个关键软件是 CUDA 工具包和 PGI 社区版。

由于本书主要涵盖了利用 CUDA 10.x 的最新 GPU 特性，为了充分利用所有的培训材料，最新的 GPU 架构(Pascal onward)将是有益的。虽然并非所有章节都需要最新的 GPU，但拥有最新的 GPU 将有助于您重现书中取得的成果。每一章在*技术要求*部分都有关于首选或必备 GPU 架构的章节。

# 下载示例代码文件

你可以从你在[www.packt.com](http://www.packt.com)的账户下载这本书的示例代码文件。如果您在其他地方购买了这本书，您可以访问[www.packtpub.com/support](https://www.packtpub.com/support)并注册将文件直接通过电子邮件发送给您。

您可以按照以下步骤下载代码文件:

1.  登录或注册[www.packt.com](http://www.packt.com)。
2.  选择“支持”选项卡。
3.  点击代码下载。
4.  在搜索框中输入图书的名称，并按照屏幕指示进行操作。

下载文件后，请确保使用最新版本的解压缩文件夹:

*   视窗系统的 WinRAR/7-Zip
*   zipeg/izp/un ARX for MAC
*   适用于 Linux 的 7-Zip/PeaZip

这本书的代码包也托管在 https://github.com/PacktPublishing/Learn-CUDA-Programming 的 GitHub 上。如果代码有更新，它将在现有的 GitHub 存储库中更新。

我们还有来自丰富的图书和视频目录的其他代码包，可在**[【https://github.com/PacktPublishing/】](https://github.com/PacktPublishing/)**获得。看看他们！

# 下载彩色图像

我们还提供了一个 PDF 文件，其中包含本书中使用的截图/图表的彩色图像。可以在这里下载:[https://static . packt-cdn . com/downloads/9781788996242 _ color images . pdf](_ColorImages.pdf)。

# 使用的约定

本书通篇使用了许多文本约定。

`CodeInText`:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟网址、用户输入和推特句柄。这里有一个例子:“注意`cudaMemcpy`有一个异步替代方案。”

代码块设置如下:

```cpp
#include<stdio.h>
#include<stdlib.h>

__global__ void print_from_gpu(void) {
    printf("Hello World! from thread [%d,%d] \
        From device\n", threadIdx.x,blockIdx.x);
}
```

当我们希望将您的注意力吸引到代码块的特定部分时，相关的行或项目以粗体显示:

```cpp
int main(void) {
    printf("Hello World from host!\n");
    print_from_gpu<<<1,1>>>();
    cudaDeviceSynchronize();
    return 0;
}
```

任何命令行输入或输出都编写如下:

```cpp
$ nvcc -o hello_world hello_world.cu
```

**粗体**:表示一个新的术语、一个重要的单词或者你在屏幕上看到的单词。例如，菜单或对话框中的单词像这样出现在文本中。下面是一个例子:“对于 Windows 用户，在 VS 项目属性对话框中，您可以在 CUDA C/C++ |设备|代码生成时指定您的 GPU 的计算能力。”

Warnings or important notes appear like this. Tips and tricks appear like this.

# 取得联系

我们随时欢迎读者的反馈。

**一般反馈**:如果你对这本书的任何方面有疑问，在你的信息主题中提到书名，发邮件给我们`customercare@packtpub.com`。

**勘误表**:虽然我们已经尽了最大的努力来保证内容的准确性，但是错误还是会发生。如果你在这本书里发现了一个错误，如果你能向我们报告，我们将不胜感激。请访问[www.packtpub.com/support/errata](https://www.packtpub.com/support/errata)，选择您的图书，点击勘误表提交链接，并输入详细信息。

**盗版**:如果您在互联网上遇到任何形式的我们作品的非法拷贝，如果您能提供我们的位置地址或网站名称，我们将不胜感激。请通过`copyright@packt.com`联系我们，并提供材料链接。

**如果你有兴趣成为一名作者**:如果有一个你有专长的话题，你有兴趣写或者投稿一本书，请访问[authors.packtpub.com](http://authors.packtpub.com/)。

# 复习

请留下评论。一旦你阅读并使用了这本书，为什么不在你购买它的网站上留下评论呢？然后，潜在的读者可以看到并使用您不带偏见的意见来做出购买决定，我们在 Packt 可以了解您对我们产品的看法，我们的作者可以看到您对他们的书的反馈。谢谢大家！

更多关于 Packt 的信息，请访问[packt.com](http://www.packt.com/)。